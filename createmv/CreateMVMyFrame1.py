"""Subclass of MyFrame1, which is generated by wxFormBuilder."""

import os
import subprocess
import tempfile

import cv2
import numpy as np
import wx
import App

from moviepy.video.io.VideoFileClip import VideoFileClip
from moviepy.audio.io.AudioFileClip import AudioFileClip
from moviepy.video.VideoClip import proglog
from pydub import AudioSegment

os.chdir(tempfile.gettempdir())


WIDTH = 800
HEIGHT = 600
PREVIEW_WIDTH = 600
PREVIEW_HEIGHT = 450
FPS = 60
SAMPLE_RATE = 44100
FRAME_SIZE = 2048  
SAMPLING_SIZE = FRAME_SIZE * 4
INT16_MAX = 32767
DEFAULT_IMAGE = np.full((HEIGHT, WIDTH, 3), 0, dtype=np.uint8)
DEFAULT_PREVIEW_IMAGE = np.full((PREVIEW_HEIGHT, PREVIEW_WIDTH, 3), 0, dtype=np.uint8)

preview_data = [208.93320214897923, 111.87468812584916, 0.0, 0.0, 141.79913989362706, 0.0, 0.0, 172.51773040353802, 0.0, 202.07527079245563, 0.0, 228.45497022168178, 249.74519854154664, 0.0, 264.296917757219, 270.85686426280137, 268.6699005107386, 0.0, 257.5482369230068, 237.91035896748986, 210.8021302801421, 321.7449405865618, 106.49551159806714, 79.04183317689527, 70.89378972959423, 191.83214385722223, 276.3588700835531, 157.5324027144556, 304.7764892732505, 280.0348884621842, 119.45034525553439, 167.90321184220994, 323.2078735832823, 275.97601394972486, 281.7571045484443, 376.3893228427966, 172.27522087289435, 336.0518375323326, 368.29843211808554, 296.1844387123827, 283.36389689375386, 335.18250276684864, 352.52080811797987, 395.2311769588005, 332.56862703633533, 326.3518720009661, 353.3927108563122, 199.1631010941759, 213.62206408295395, 310.1209382766217, 310.3951480248984, 398.5869615937684, 312.296603106399, 361.43133512491914, 319.2285615508598, 361.82886211521884, 306.1923617333016, 382.8543769392828, 348.97075736198593, 389.9409655580049, 354.26383982749064, 342.4513416170773, 349.6279529175187, 365.16789311586757, 338.78190400803885, 297.8917554795074, 329.3776542034391, 331.1487544648564, 154.5264551810376, 123.95108732403608, 61.701525692720004, 61.24687917769049, 63.706750544235284, 66.02103466886973, 69.74300526696166, 74.17618640321732]
spectram_range = [int(22050 / 2 ** (i/10)) for i in range(100, -1,-1)]
freq = np.abs(np.fft.fftfreq(SAMPLING_SIZE, d=(1/SAMPLE_RATE)))
spectram_array = (freq <= spectram_range[0]).reshape(1,-1)
for index in range(1, len(spectram_range)):
    tmp_freq = ((freq > spectram_range[index - 1]) & (freq <= spectram_range[index])).reshape(1,-1)
    spectram_array = np.append(spectram_array, tmp_freq, axis=0)
part_w = WIDTH / len(spectram_range)
preview_part_w = PREVIEW_WIDTH / len(spectram_range)


class WriteVideoProgress(proglog.ProgressBarLogger):
    def __init__(self, progress, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.progress = progress
        self.reading_audio = False
    
    def callback(self, *_, **__):
        pass

    def bars_callback(self, bar, attr, value, old_value=None):
        total = self.bars[bar]["total"]
        p = int(value / total * 100)
        if old_value is None:
            self.reading_audio = not self.reading_audio
            self.msg = "音声の読み込み中...  {}/{}" if self.reading_audio else "動画の書き出し中...  {}/{}"
        self.progress.Update(99 if 100 <= p else p, newmsg=self.msg.format(value, total))
        

# Implementing MyFrame1
class CreateMVMyFrame1( App.MyFrame1 ):
    def __init__( self, parent ):
        App.MyFrame1.__init__( self, parent )
        self.shapes = {0: draw_horizon, 1: draw_circle}
        self.colors = {0: (0, 0, 255), 1: (255, 0, 0), 2: (0, 255, 0), 3: (0, 255, 255), 4: (0, 0, 0), 5:(255, 255, 255)}
        try:
            subprocess.run("ffmpeg", stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        except:
            wx.MessageBox("ffmpegがインストールされていない、またはPathが通っていないため\nmp3など一部形式に対応していません", "警告", wx.ICON_EXCLAMATION)
        self.show_preview(None)

    # Handlers for MyFrame1 events.
    def m_button11OnButtonClick( self, event ):
        # TODO: Implement m_button11OnButtonClick
        dlg = wx.DirDialog(self, message="保存先ディレクトリ")
        if dlg.ShowModal() == wx.ID_OK:
            self.m_textCtrl16.SetValue(dlg.GetPath())

    def m_button8OnButtonClick( self, event ):
        # TODO: Implement m_button8OnButtonClick
        dlg = wx.FileDialog(self, message="音声ファイル")
        if dlg.ShowModal() == wx.ID_OK:
            self.m_textCtrl14.SetValue(dlg.GetPath())

    def m_button9OnButtonClick( self, event ):
        # TODO: Implement m_button9OnButtonClick
        dlg = wx.FileDialog(self, message="背景画像")
        if dlg.ShowModal() == wx.ID_OK:
            self.m_textCtrl15.SetValue(dlg.GetPath())

    def m_slider1OnSlider( self, event ):
        n = self.m_slider1.GetValue()
        self.m_textCtrl4.SetValue(str(n / 100))
        self.show_preview(event)

    def m_textCtrl4OnText( self, event ):
        n = self.m_textCtrl4.GetValue()
        try:
            self.m_slider1.SetValue(int(float(n) * 100))
            self.show_preview(event)
        except:
            self.m_textCtrl4.SetValue(str(self.m_slider1.GetValue() / 100))

    def m_slider2OnSlider( self, event ):
        n = self.m_slider2.GetValue()
        self.m_textCtrl5.SetValue(str(n / 100))
        self.show_preview(event)

    def m_textCtrl5OnText( self, event ):
        n = self.m_textCtrl5.GetValue()
        try:
            self.m_slider2.SetValue(int(float(n) * 100))
            self.show_preview(event)
        except:
            self.m_textCtrl5.SetValue(str(self.m_slider2.GetValue() / 100))

    def m_button10OnButtonClick( self, event ):
        # TODO: Implement m_button10OnButtonClick
        dlg1 = wx.ProgressDialog(title="CMV", message="読み込み中...", style=wx.PD_APP_MODAL | wx.PD_ESTIMATED_TIME | wx.PD_REMAINING_TIME)
        dlg1.Show()
        audio_file = self.m_textCtrl14.GetValue()
        if not os.path.isfile(audio_file):
            self.m_staticText13.SetLabel("音声ファイルが指定されていないかファイルが\n存在しません")
            dlg.Close()
            self.Refresh()
            return
        try:
            audio = AudioSegment.from_file(audio_file)
            sample = np.array_split(np.array(audio.get_array_of_samples())[::audio.channels], int(FPS * audio.duration_seconds))
            length = len(sample)
        except:
            self.m_staticText13.SetLabel("この音声形式に対応していません。拡張子等を\n見直してください")
            dlg.Close()
            self.Refresh()
            return
        save_path = self.m_textCtrl16.GetValue()
        if not save_path:
            self.m_staticText13.SetLabel("保存先が指定されていません")
            dlg.Close()
            self.Refresh()
            return
        if os.path.isdir(save_path):
            save_filename = os.path.join(save_path, os.path.splitext(os.path.basename(audio_file))[0] + ".mp4")
        else:
            if not os.path.isdir(os.path.dirname(save_path)):
                os.makedirs(os.path.dirname(save_path))
            if not save_path.endswith(".mp4"):
                save_filename = save_path.rstrip(".") + ".mp4"
            else:
                save_filename = save_path
        image_file = self.m_textCtrl15.GetValue()
        try:
            img = cv2.resize(cv2.imread(image_file), (WIDTH, HEIGHT))
        except:
            img = DEFAULT_IMAGE
        beta = self.m_slider1.GetValue()
        alpha = self.m_slider2.GetValue() / 100
        beta_spectram = 1 - alpha
        image = cv2.convertScaleAbs(img, beta=beta)
        self.m_staticText13.SetLabel("")
        draw = self.shapes[self.m_choice2.GetSelection()]
        color = self.colors[self.m_choice3.GetSelection()]
        fourcc = cv2.VideoWriter_fourcc("m", "p", "4", "v")
        with tempfile.TemporaryDirectory() as temp:
            temp_video = os.path.join(temp, ".mp4")
            video = cv2.VideoWriter(temp_video, fourcc, FPS, (WIDTH, HEIGHT))
            sampling_data = np.zeros(SAMPLING_SIZE)
            for n, s in enumerate(sample, start=1):
                draw_image = image.copy()
                sampling_data = np.concatenate([sampling_data, np.frombuffer(s.copy(order="C"), dtype="int16") / INT16_MAX])
                if sampling_data.shape[0] > SAMPLING_SIZE:
                    sampling_data = sampling_data[-SAMPLING_SIZE:]
                fft = np.abs(np.fft.fft(sampling_data))
                spectram_data = np.dot(spectram_array, fft)
                for index, value in enumerate(spectram_data):
                    draw(index, value, draw_image, spectram_data, color)
                video.write(cv2.addWeighted(draw_image, alpha, image, beta_spectram, 0))
                progress = int(n / length * 100)
                dlg1.Update(99 if 100 <= progress else progress, newmsg=f"オーディオスペクトラムを作成中...  {n}/{length}")
            video.release()
            dlg1.Close()
            dlg2 = wx.ProgressDialog(title="CMV", message="読み込み中...", style=wx.PD_APP_MODAL | wx.PD_ESTIMATED_TIME | wx.PD_REMAINING_TIME)
            dlg2.Show()
            clip = VideoFileClip(temp_video)
            mv = clip.set_audio(AudioFileClip(audio_file))
            mv.write_videofile(save_filename, verbose=False, logger=WriteVideoProgress(dlg2))
            dlg2.Update(100, newmsg="処理が完了しました")
            
    def show_preview( self, event ):
        path = self.m_textCtrl15.GetValue()
        draw = self.shapes[self.m_choice2.GetSelection()]
        color = self.colors[self.m_choice3.GetSelection()]
        beta = self.m_slider1.GetValue()
        alpha = self.m_slider2.GetValue() / 100
        image = cv2.convertScaleAbs(cv2.imread(path) if os.path.isfile(path) else DEFAULT_PREVIEW_IMAGE, beta=beta)
        draw_image = image.copy()
        for i, v in enumerate(preview_data):
            draw(i, v, draw_image, preview_data, color, preview=True)
        preview = cv2.addWeighted(draw_image, alpha, image, 1 - alpha, 0)
        buf = cv2.cvtColor(preview, cv2.COLOR_BGR2RGB)
        bmp = wx.Bitmap.FromBuffer(image.shape[1], image.shape[0], buf)
        self.m_bitmap2.SetBitmap(bmp)

def draw_horizon(i, v, img, s, c, preview=False):
    w = PREVIEW_WIDTH if preview else WIDTH
    h = PREVIEW_HEIGHT if preview else HEIGHT
    part = preview_part_w if preview else part_w
    cv2.rectangle(img, (int(part * i + 1), h), (int(part * (i + 1) - 1), int(max(h - v/(1 if preview else 16), 0))), c, thickness=-5)

def draw_circle(i, v, img, s, c, preview=False):
    w = PREVIEW_WIDTH if preview else WIDTH
    h = PREVIEW_HEIGHT if preview else HEIGHT
    rad = (2 * np.pi) * (i / len(s))
    x1 = int(w / 2 + np.sin(rad) * 80)
    y1 = int(h / 2 - np.cos(rad) * 80)
    x2 = int(w / 2 + np.sin(rad) * (80 + v/32))
    y2 = int(h / 2 - np.cos(rad) * (80 + v/32))
    cv2.line(img, (x1, y1), (x2, y2), c, thickness=2)
